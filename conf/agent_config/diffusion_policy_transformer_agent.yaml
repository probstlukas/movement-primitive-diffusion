_target_: movement_primitive_diffusion.agents.discrete_time_diffusion_agent.DiscreteTimeDiffusionAgent
_recursive_: False

defaults:
  - model_config: diffusion_model
  - noise_scheduler_config: discrete_time_ddpm
  - override model_config/inner_model_config: transformer
  - override model_config/scaling_config: absolute_scaling
  - _self_

device: null  # set in python based on main config

num_inference_steps: 5 # either 100 or 8 in Diffusion Policy configs. If none -> takes the num_training_steps from the noise_scheduler_config

t_obs: ${t_obs}
predict_past: ${predict_past}

use_ema: True
ema_config:
  decay: 0.9999
  min_decay: 0.0
  update_after_step: 0
  use_ema_warmup: True # https://github.com/columbia-ai-robotics/diffusion_policy/blob/main/diffusion_policy/model/diffusion/ema_model.py#L49
  inv_gamma: 1.0
  power: 0.75 # https://github.com/columbia-ai-robotics/diffusion_policy/blob/main/diffusion_policy/model/diffusion/ema_model.py#L20

special_optimizer_function: True # -> call configure_optimizer function of inner model with special_optimizer_config parameters. Else use optimizer_config
special_optimizer_config:
  model_weight_decay: 1.0e-3
  encoder_weight_decay: 1.0e-6
  learning_rate: 1.0e-4
  betas: [0.9, 0.95]
  eps: 1.0e-8

optimizer_config: null

lr_scheduler_config:
  _target_: movement_primitive_diffusion.utils.lr_scheduler.get_scheduler
  name: cosine
  num_warmup_steps: 1000 # mostly 500 or 1000
  num_training_steps: null # set in python based on dataloader size and number of epochs to train
  last_epoch: -1 # use the current epoch. Can be adjusted to continue training.
